# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(Country = country_names, Link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_data <- extract_crt_links(webpage)
View(crt_data)
library(countrycode)
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
# Function to extract links with title "CRT"
extract_crt_links <- function(webpage) {
tryCatch({
# Select anchor (<a>) elements where title contains "CRT"
elements <- webpage %>%
html_elements("a[title*='CRT']")  # Matches any <a> tag with 'CRT' in the title
# Extract href (link) and title
links <- elements %>% html_attr("href")
titles <- elements %>% html_attr("title")
if (length(links) == 0) {
message("No CRT links found on the page.")
return(NULL)
} else {
# Prepend the base URL to form complete links
base_url <- "https://unfccc.int"
full_links <- sapply(links, function(link) {
if (startsWith(link, "/")) {
paste0(base_url, link)
} else {
link
}
})
# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_data <- extract_crt_links(webpage)
crt_data <- crt_data %>%
mutate(iso=countrycode(country,country.name,iso3c))
??countrycode
crt_data <- crt_data %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
crt_links <- extract_crt_links(webpage)
crt_links <- crt_links %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
load("data/data_crt_files.RData")
View(files_crts)
crt_links <- left_join(crt_links,files_crts %>% select(dir,iso) %>% distinct(),by="iso")
blarg <- files_crts %>% select(dir,iso) %>% distinct()
View(blarg)
View(crt_links)
crt_links <- crt_links %>% filter(is.na(dir))
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(openxlsx)
library(tidyverse)
library(countrycode)
library(zoo)
## download files from https://unfccc.int/ghg-inventories-annex-i-parties/2024
# run scan_files.R
load("data/data_crt_files.RData")
source("https://raw.githubusercontent.com/lambwf/Codebase/main/figure_style.R")
# Table10s1, Table10s2, Table10s3, Table10s4, Table10s5, Table10s6
# Assume GWP is always AR5
#data_crts <- data.frame(country=NA,year_submission=NA,gwp=NA,gas=NA,year=NA,category=NA,value=NA)
## for the summary sheets we only need the file for the latest year
files_crts <- files_crts %>%
arrange(iso,file_year) %>%
group_by(iso) %>%
mutate(include=ifelse(file_year==last(file_year),1,0)) %>%
filter(include==1)
data_crts <- data.frame()
data_memos <- data.frame()
files_crts <- files_crts %>%
filter(country!="Maldives") %>%
filter(country!="Ecuador")
i=9
for (i in 1:length(files_crts$country)) {
table_1 <- read.xlsx(xlsxFile = paste0("sources/CRTs/",files_crts$dir[i],"/",files_crts$files[i]),
sheet = paste0("Table10s1"),
startRow = 8) %>%
select("GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES",matches("^\\d{4}")) %>%
rename_with(~ substr(., 1, 4), matches("^\\d{4}")) %>%
mutate(units = "ktCO2e") %>%
mutate(gas = "ghg") %>%
mutate(across(matches("^\\d{4}$"), as.character))
table_2 <- read.xlsx(xlsxFile = paste0("sources/CRTs/",files_crts$dir[i],"/",files_crts$files[i]),
sheet = paste0("Table10s2"),
startRow = 8) %>%
select("GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES",matches("^\\d{4}")) %>%
rename_with(~ substr(., 1, 4), matches("^\\d{4}")) %>%
mutate(units = "ktCO2") %>%
mutate(gas = "co2") %>%
mutate(across(matches("^\\d{4}$"), as.character))
table_3 <- read.xlsx(xlsxFile = paste0("sources/CRTs/",files_crts$dir[i],"/",files_crts$files[i]),
sheet = paste0("Table10s3"),
startRow = 8) %>%
select("GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES",matches("^\\d{4}")) %>%
rename_with(~ substr(., 1, 4), matches("^\\d{4}")) %>%
mutate(units = "ktCH4e") %>%
mutate(gas = "ch4") %>%
mutate(across(matches("^\\d{4}$"), as.character))
table_4 <- read.xlsx(xlsxFile = paste0("sources/CRTs/",files_crts$dir[i],"/",files_crts$files[i]),
sheet = paste0("Table10s4"),
startRow = 8) %>%
select("GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES",matches("^\\d{4}")) %>%
rename_with(~ substr(., 1, 4), matches("^\\d{4}")) %>%
mutate(units = "ktN2O") %>%
mutate(gas = "n2o") %>%
mutate(across(matches("^\\d{4}$"), as.character))
table_5 <- read.xlsx(xlsxFile = paste0("sources/CRTs/",files_crts$dir[i],"/",files_crts$files[i]),
sheet = paste0("Table10s5"),
startRow = 8) %>%
select("GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES",matches("^\\d{4}")) %>%
rename_with(~ substr(., 1, 4), matches("^\\d{4}")) %>%
mutate(units = "ktCO2e") %>%
mutate(gas = "fgases") %>%
mutate(across(matches("^\\d{4}$"), as.character))
table_6 <- read.xlsx(xlsxFile = paste0("sources/CRTs/",files_crts$dir[i],"/",files_crts$files[i]),
sheet = paste0("Table10s6"),
startRow = 8) %>%
select("GREENHOUSE.GAS.EMISSIONS.AND.REMOVALS",matches("^\\d{4}")) %>%
rename_with(~ substr(., 1, 4), matches("^\\d{4}")) %>%
mutate(units = "ktCO2e") %>%
mutate(gas = "totals") %>%
mutate(across(matches("^\\d{4}$"), as.character))
## fix up f-gas table
table_5 <- table_5 %>%
mutate(gas=GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES) %>%
mutate(GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES="2.F. Product uses as substitutes for ODS")
table_5 <- table_5 %>%
filter(gas %in% c("Emissions of HFCs -  CO2 equivalents (kt) (3)",
"Emissions of PFCs -  CO2 equivalents (kt) ",
"Emissions of  SF6 -  CO2 equivalents (kt) (3)",
"Emissions of NF3 - CO2 equivalents (kt) (3)",
"Unspecified mix of  HFCs and PFCs - CO2 equivalents (kt) (3)")) %>%
mutate(gas=ifelse(grepl("Unspecified",gas),"hfcs/pfcs (unspecified)",gas)) %>%
mutate(gas=ifelse(grepl("HFCs",gas),"hfcs",gas)) %>%
mutate(gas=ifelse(grepl("PFCs",gas),"pfcs",gas)) %>%
mutate(gas=ifelse(grepl("SF6",gas),"sf6",gas)) %>%
mutate(gas=ifelse(grepl("NF3",gas),"nf3",gas))
## merge co2, ch4, n2o, fgases
table <- bind_rows(table_2,table_3,table_4,table_5)
table <- table %>%
select(sector=GREENHOUSE.GAS.SOURCE.AND.SINK.CATEGORIES,gas,units,everything()) %>%
filter(!is.na(sector)) %>%
filter(!grepl("Note:",sector))
table <- gather(table,year,value,-sector,-gas,-units)
## deal with NA, NO, IE, NE
table <- table %>%
mutate(value=ifelse(grepl("NA",value),NA,value)) %>% #
mutate(value=ifelse(grepl("IE",value),NA,value)) %>% # Indicated elsewhere
mutate(value=ifelse(grepl("NE",value),NA,value)) %>% # Not estimated
mutate(value=ifelse(grepl("NO",value),0,value)) # Not occurring
## extract sector codes
table <- table %>%
mutate(sector_code=sub("^(\\S+)\\s.*", "\\1", sector)) %>%
mutate(sector=sub("^\\S+\\s(.*)", "\\1", sector))
## remove spaces at the beginning of categories
table$sector <- gsub("^\\s+", "", table$sector)
## extract the emissions hierarchy (just the level associated with each sector)
table <- table %>%
mutate(sector_level = map_int(sector_code, ~ sum(str_split(.x, "\\.")[[1]] != "")))
## remove memo items etc.
memos <- table %>%
filter(grepl("1.D.",sector_code) | grepl("5.F.1.",sector_code))
table <- table %>%
filter(!sector_code %in% c("Memo","Indirect","Total")) %>%
filter(!grepl("1.D.",sector_code)) %>%
filter(!grepl("5.F.1.",sector_code))
## clean up
table <- table %>%
mutate(country=files_crts$country[i]) %>%
mutate(iso=files_crts$iso[i]) %>%
select(iso,country,sector_code,sector_description=sector,sector_level,gas,units,year,value) %>%
mutate(value=as.numeric(value)) %>%
mutate(year=as.numeric(year))
memos <- memos %>%
mutate(country=files_crts$country[i]) %>%
mutate(iso=files_crts$iso[i]) %>%
select(country,iso,sector_code,sector_description=sector,sector_level,gas,units,year,value) %>%
mutate(value=as.numeric(value)) %>%
mutate(year=as.numeric(year))
## bind to dataset
data_crts <- bind_rows(data_crts,table)
data_memos <- bind_rows(data_memos,memos)
}
rm(list=ls())
library(rvest)
library(httr)
library(countrycode)
# Function to fetch and parse the webpage
fetch_webpage <- function(url) {
tryCatch({
page <- GET(url)
if (status_code(page) == 200) {
content <- read_html(page)
return(content)
} else {
stop("Failed to fetch the webpage. HTTP status code: ", status_code(page))
}
}, error = function(e) {
message("Error: ", e$message)
return(NULL)
})
}
# Function to extract links with title "CRT"
extract_crt_links <- function(webpage) {
tryCatch({
# Select anchor (<a>) elements where title contains "CRT"
elements <- webpage %>%
html_elements("a[title*='CRT']")  # Matches any <a> tag with 'CRT' in the title
# Extract href (link) and title
links <- elements %>% html_attr("href")
titles <- elements %>% html_attr("title")
if (length(links) == 0) {
message("No CRT links found on the page.")
return(NULL)
} else {
# Prepend the base URL to form complete links
base_url <- "https://unfccc.int"
full_links <- sapply(links, function(link) {
if (startsWith(link, "/")) {
paste0(base_url, link)
} else {
link
}
})
# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_links <- extract_crt_links(webpage)
crt_links <- crt_links %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
rm(list=ls())
library(rvest)
library(httr)
library(countrycode)
# Function to fetch and parse the webpage
fetch_webpage <- function(url) {
tryCatch({
page <- GET(url)
if (status_code(page) == 200) {
content <- read_html(page)
return(content)
} else {
stop("Failed to fetch the webpage. HTTP status code: ", status_code(page))
}
}, error = function(e) {
message("Error: ", e$message)
return(NULL)
})
}
# Function to extract links with title "CRT"
extract_crt_links <- function(webpage) {
tryCatch({
# Select anchor (<a>) elements where title contains "CRT"
elements <- webpage %>%
html_elements("a[title*='CRT']")  # Matches any <a> tag with 'CRT' in the title
# Extract href (link) and title
links <- elements %>% html_attr("href")
titles <- elements %>% html_attr("title")
if (length(links) == 0) {
message("No CRT links found on the page.")
return(NULL)
} else {
# Prepend the base URL to form complete links
base_url <- "https://unfccc.int"
full_links <- sapply(links, function(link) {
if (startsWith(link, "/")) {
paste0(base_url, link)
} else {
link
}
})
# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_links <- extract_crt_links(webpage)
crt_links <- crt_links %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
load("data/data_crt_files.RData")
crt_links <- left_join(crt_links,files_crts %>% select(dir,iso) %>% distinct(),by="iso")
crt_links <- crt_links %>% filter(is.na(dir))
View(crt_links)
rm(list=ls())
library(rvest)
library(httr)
library(countrycode)
# Function to fetch and parse the webpage
fetch_webpage <- function(url) {
tryCatch({
page <- GET(url)
if (status_code(page) == 200) {
content <- read_html(page)
return(content)
} else {
stop("Failed to fetch the webpage. HTTP status code: ", status_code(page))
}
}, error = function(e) {
message("Error: ", e$message)
return(NULL)
})
}
# Function to extract links with title "CRT"
extract_crt_links <- function(webpage) {
tryCatch({
# Select anchor (<a>) elements where title contains "CRT"
elements <- webpage %>%
html_elements("a[title*='CRT']")  # Matches any <a> tag with 'CRT' in the title
# Extract href (link) and title
links <- elements %>% html_attr("href")
titles <- elements %>% html_attr("title")
if (length(links) == 0) {
message("No CRT links found on the page.")
return(NULL)
} else {
# Prepend the base URL to form complete links
base_url <- "https://unfccc.int"
full_links <- sapply(links, function(link) {
if (startsWith(link, "/")) {
paste0(base_url, link)
} else {
link
}
})
# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_links <- extract_crt_links(webpage)
crt_links <- crt_links %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
rm(list=ls())
library(rvest)
library(httr)
library(countrycode)
# Function to fetch and parse the webpage
fetch_webpage <- function(url) {
tryCatch({
page <- GET(url)
if (status_code(page) == 200) {
content <- read_html(page)
return(content)
} else {
stop("Failed to fetch the webpage. HTTP status code: ", status_code(page))
}
}, error = function(e) {
message("Error: ", e$message)
return(NULL)
})
}
# Function to extract links with title "CRT"
extract_crt_links <- function(webpage) {
tryCatch({
# Select anchor (<a>) elements where title contains "CRT"
elements <- webpage %>%
html_elements("a[title*='CRT']")  # Matches any <a> tag with 'CRT' in the title
# Extract href (link) and title
links <- elements %>% html_attr("href")
titles <- elements %>% html_attr("title")
if (length(links) == 0) {
message("No CRT links found on the page.")
return(NULL)
} else {
# Prepend the base URL to form complete links
base_url <- "https://unfccc.int"
full_links <- sapply(links, function(link) {
if (startsWith(link, "/")) {
paste0(base_url, link)
} else {
link
}
})
# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_links <- extract_crt_links(webpage)
crt_links <- crt_links %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
rm(list=ls())
library(rvest)
library(httr)
library(countrycode)
library(tidyverse)
# Function to fetch and parse the webpage
fetch_webpage <- function(url) {
tryCatch({
page <- GET(url)
if (status_code(page) == 200) {
content <- read_html(page)
return(content)
} else {
stop("Failed to fetch the webpage. HTTP status code: ", status_code(page))
}
}, error = function(e) {
message("Error: ", e$message)
return(NULL)
})
}
# Function to extract links with title "CRT"
extract_crt_links <- function(webpage) {
tryCatch({
# Select anchor (<a>) elements where title contains "CRT"
elements <- webpage %>%
html_elements("a[title*='CRT']")  # Matches any <a> tag with 'CRT' in the title
# Extract href (link) and title
links <- elements %>% html_attr("href")
titles <- elements %>% html_attr("title")
if (length(links) == 0) {
message("No CRT links found on the page.")
return(NULL)
} else {
# Prepend the base URL to form complete links
base_url <- "https://unfccc.int"
full_links <- sapply(links, function(link) {
if (startsWith(link, "/")) {
paste0(base_url, link)
} else {
link
}
})
# Extract country names (assume the first word(s) before the first period in the title)
country_names <- sapply(titles, function(title) {
strsplit(title, "\\.", fixed = FALSE)[[1]][1]
})
# Combine country names and links into a data frame
result <- data.frame(country = country_names, link = full_links, stringsAsFactors = FALSE)
return(result)
}
}, error = function(e) {
message("Error during link extraction: ", e$message)
return(NULL)
})
}
##
webpage <- fetch_webpage("https://unfccc.int/first-biennial-transparency-reports")
crt_links <- extract_crt_links(webpage)
crt_links <- crt_links %>%
mutate(iso=countrycode(country,'country.name','iso3c'))
load("data/data_crt_files.RData")
crt_links <- left_join(crt_links,files_crts %>% select(dir,iso) %>% distinct(),by="iso")
crt_links <- crt_links %>% filter(is.na(dir))
View(crt_links)
